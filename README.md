# Reconhecimento de Sinais  em Tempo Real

![IMG](IMGS/PIC.png)


**Traduza gestos  em texto em tempo real usando sua webcam!** Este projeto utiliza vis√£o computacional e aprendizado profundo para construir um sistema interativo de reconhecimento de sinais.

---

## üìú Sum√°rio

- [üåü Funcionalidades Principais](#-funcionalidades-principais)
- [üöÄ Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [üõ†Ô∏è Estrutura do Projeto](#Ô∏è-estrutura-do-projeto)
- [üìã Pr√©-requisitos](#-pr√©-requisitos)
- [üì¶ Instala√ß√£o](#-instala√ß√£o)
- [üéÆ Como Usar](#-como-usar)
  - [Executando a Aplica√ß√£o Principal](#executando-a-aplica√ß√£o-principal)
  - [üìä Coleta de Dados](#-coleta-de-dados)
  - [üß† Treinando um Novo Modelo](#-treinando-um-novo-modelo)
  - [‚öôÔ∏è Configura√ß√µes da Aplica√ß√£o](#Ô∏è-configura√ß√µes-da-aplica√ß√£o)
- [üîß Detalhes T√©cnicos](#-detalhes-t√©cnicos)
  - [Extra√ß√£o de Caracter√≠sticas](#extra√ß√£o-de-caracter√≠sticas)
  - [Arquitetura do Modelo](#arquitetura-do-modelo)
- [üìà Resultados e Avalia√ß√£o](#-resultados-e-avalia√ß√£o)
- [üîÆ Poss√≠veis Melhorias Futuras](#-poss√≠veis-melhorias-futuras)
- [ü§ù Contribui√ß√µes](#-contribui√ß√µes)
- [üìÑ Licen√ßa](#-licen√ßa)
- [üìß Contato](#-contato)

---

## üåü Funcionalidades Principais

- **üé• Reconhecimento em Tempo Real**: Detecta e classifica gestos de Libras diretamente da sua webcam.
- **üìä Coleta de Dados Intuitiva**: Interface gr√°fica para capturar, nomear e salvar sequ√™ncias de gestos para criar ou expandir datasets de treinamento.
- **üß† Treinamento de Modelo Simplificado**: Script dedicado (`TrainModel.py`) para treinar modelos LSTM bidirecionais com os dados coletados, incluindo visualiza√ß√£o de m√©tricas.
- **üñ•Ô∏è Interface Gr√°fica Amig√°vel**: Aplica√ß√£o desktop constru√≠da com Tkinter, organizada em abas para f√°cil navega√ß√£o entre coleta, reconhecimento e configura√ß√µes.
- **‚öôÔ∏è Par√¢metros Configur√°veis**: Ajuste de sensibilidade de detec√ß√£o, limiares de confian√ßa e outros par√¢metros diretamente na interface.
- **üìù Feedback Visual e Textual**: Exibe os gestos detectados, a frase formada e o hist√≥rico de reconhecimentos.

---

## üöÄ Tecnologias Utilizadas

- **Linguagem**: Python 3.8+
- **Vis√£o Computacional**: OpenCV, MediaPipe (Holistic para detec√ß√£o de pose, face e m√£os)
- **Aprendizado Profundo**: TensorFlow, Keras (para constru√ß√£o e treinamento de modelos LSTM)
- **Interface Gr√°fica (GUI)**: Tkinter
- **Manipula√ß√£o de Dados**: NumPy
- **Visualiza√ß√£o**: Matplotlib, Seaborn (usados no script de treinamento)
- **Gerenciamento de Depend√™ncias**: Pip com `requirements.txt`

---

## üõ†Ô∏è Estrutura do Projeto

```
TrainingDet/
‚îÇ
‚îú‚îÄ‚îÄ main.py                  # Aplica√ß√£o principal com interface gr√°fica (GUI)
‚îú‚îÄ‚îÄ TrainModel.py            # Script para treinamento do modelo de reconhecimento
‚îú‚îÄ‚îÄ requirements.txt         # Lista de depend√™ncias do projeto
‚îú‚îÄ‚îÄ README.md                # Este arquivo de documenta√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ Sign_Data_App/           # Diret√≥rio para dados de gestos coletados
‚îÇ   ‚îî‚îÄ‚îÄ [nome_da_acao]/      # Ex: 'Beleza', 'Obrigado', 'Ola'
‚îÇ       ‚îî‚îÄ‚îÄ [numero_sequencia]/ # Sequ√™ncias de v√≠deo (0, 1, 2, ...)
‚îÇ           ‚îî‚îÄ‚îÄ [frame_num].npy # Keypoints extra√≠dos por frame (formato NumPy)
‚îÇ
‚îú‚îÄ‚îÄ Models/                  # Modelos de Keras treinados e salvos
‚îÇ   ‚îî‚îÄ‚îÄ sign_language_model.keras # Exemplo de modelo treinado
‚îÇ
‚îî‚îÄ‚îÄ Logs/                    # Logs de treinamento para visualiza√ß√£o no TensorBoard
    ‚îî‚îÄ‚îÄ [timestamp_treino]/  # Arquivos de log para cada sess√£o de treinamento
```

---

## üìã Pr√©-requisitos

- Python 3.8 ou superior.
- Pip (gerenciador de pacotes Python).
- Uma webcam conectada e funcionando.
- (Opcional) Git para clonar o reposit√≥rio.

---

## üì¶ Instala√ß√£o

1. **Clone o reposit√≥rio:**

   ```bash
   git clone https://github.com/JPEDROPS092/GestosRecon
   cd TrainingDet
   ```

   (Se voc√™ n√£o tem Git, pode baixar o ZIP do projeto e extra√≠-lo)
2. **Crie e ative um ambiente virtual (recomendado):**

   ```bash
   python -m venv venv
   # No Windows
   venv\Scripts\activate
   # No macOS/Linux
   source venv/bin/activate
   ```
3. **Instale as depend√™ncias:**

   ```bash
   pip install -r requirements.txt
   ```

   *Nota: A instala√ß√£o do TensorFlow pode levar alguns minutos.*

---

## üéÆ Como Usar

### Executando a Aplica√ß√£o Principal

Para iniciar a interface gr√°fica do sistema de reconhecimento:

```bash
python main.py
```

A aplica√ß√£o possui tr√™s abas principais:

1. **C√¢mera**: Configura e visualiza o feed da webcam.
2. **Coleta de Dados**: Para gravar novos gestos.
3. **Reconhecimento**: Para usar o modelo treinado e reconhecer gestos em tempo real.

![Screenshot da Interface (opcional)](link_para_screenshot_da_gui_se_tiver.png)
*(Considere adicionar um screenshot da sua GUI aqui)*

### üìä Coleta de Dados

Para treinar o modelo com seus pr√≥prios gestos ou adicionar novos:

1. Execute `main.py` e v√° para a aba **"Coleta de Dados"**.
2. No campo **"Nome da A√ß√£o/Gesto"**, digite o nome do gesto que voc√™ deseja gravar (ex: "Ol√°", "Ajuda", "Sim").
3. Clique em **"Iniciar Coleta para esta A√ß√£o"**.
4. A c√¢mera ser√° ativada. Siga as instru√ß√µes na tela:
   * Haver√° uma contagem regressiva antes de cada sequ√™ncia de grava√ß√£o.
   * Realize o gesto de forma clara durante a grava√ß√£o de cada sequ√™ncia.
   * O sistema gravar√° um n√∫mero pr√©-definido de sequ√™ncias (`NO_SEQUENCES`) com um n√∫mero pr√©-definido de frames por sequ√™ncia (`SEQUENCE_LENGTH`).
5. Os dados (keypoints extra√≠dos) ser√£o salvos automaticamente em `Sign_Data_App/[nome-do-gesto]/`.

**Dicas para uma boa coleta:**

* Mantenha uma boa ilumina√ß√£o.
* Evite fundos muito complexos ou com muito movimento.
* Realize os gestos de forma consistente, mas com pequenas varia√ß√µes para robustez.

### üß† Treinando um Novo Modelo

Ap√≥s coletar dados suficientes para os gestos desejados:

1. Execute o script de treinamento:
   ```bash
   python TrainModel.py
   ```
2. O script ir√°:
   * Carregar os dados da pasta `Sign_Data_App/`.
   * Pr√©-processar os dados e dividi-los em conjuntos de treino e teste.
   * Construir e treinar um modelo LSTM bidirecional.
   * Exibir m√©tricas de desempenho (ex: precis√£o, perda) e gr√°ficos (ex: matriz de confus√£o, curvas de aprendizado).
   * Salvar o modelo treinado em `Models/sign_language_model.keras` (ou similar).
   * Gerar logs de treinamento em `Logs/` para an√°lise com TensorBoard:
     ```bash
     tensorboard --logdir Logs/
     ```

### ‚öôÔ∏è Configura√ß√µes da Aplica√ß√£o

Na aba **"Reconhecimento"** da aplica√ß√£o `main.py`, voc√™ pode:

* **Carregar um Modelo**: Selecionar um arquivo `.keras` treinado.
* **Ajustes de Sensibilidade**:
  * **Limiar de Confian√ßa**: Define a confian√ßa m√≠nima para uma predi√ß√£o ser considerada.
  * **Consist√™ncia do Buffer**: Define o qu√£o consistente uma predi√ß√£o deve ser em um buffer de frames.
  * **Pausa Entre Detec√ß√µes**: Tempo de espera antes de tentar detectar um novo gesto ap√≥s uma detec√ß√£o bem-sucedida no modo cont√≠nuo.
* **Modo Cont√≠nuo**: Ativar/desativar o reconhecimento autom√°tico de gestos sem a necessidade de clicar em "Capturar Gesto".

---

## üîß Detalhes T√©cnicos

### Extra√ß√£o de Caracter√≠sticas

O sistema utiliza o **MediaPipe Holistic** para extrair um total de **1668** caracter√≠sticas num√©ricas por frame de v√≠deo:

- **Pose Landmarks (33 pontos)**: Coordenadas `x, y, z` e `visibilidade` para cada ponto (33 * 4 = 132 valores).
- **Face Landmarks (468 pontos)**: Coordenadas `x, y, z` para cada ponto (468 * 3 = 1404 valores).
- **Hand Landmarks (21 pontos por m√£o)**: Coordenadas `x, y, z` para cada ponto (21 * 3 * 2 m√£os = 126 valores).
- **Caracter√≠sticas Calculadas Adicionais (6 valores)**:
  - Dist√¢ncia da m√£o esquerda ao centro da face.
  - Dist√¢ncia da m√£o direita ao centro da face.
  - Dist√¢ncia entre o centro da m√£o esquerda e o centro da m√£o direita.
  - Dist√¢ncia entre as pontas dos dedos indicadores das duas m√£os.
  - √Çngulo do vetor (ponta do dedo indicador esquerdo -> centro da face) em rela√ß√£o a um vetor de refer√™ncia.
  - √Çngulo do vetor (ponta do dedo indicador direito -> centro da face) em rela√ß√£o a um vetor de refer√™ncia.

Estas caracter√≠sticas s√£o normalizadas e achatadas para formar o vetor de entrada para o modelo.

### Arquitetura do Modelo

O modelo de reconhecimento de gestos emprega uma arquitetura de Rede Neural Recorrente, especificamente uma **LSTM (Long Short-Term Memory) Bidirecional**, ideal para dados sequenciais como v√≠deos de gestos:

1. **Camada de Entrada**: Recebe sequ√™ncias de `SEQUENCE_LENGTH` frames, cada frame contendo 1668 caracter√≠sticas.
2. **Camadas LSTM Bidirecionais**: M√∫ltiplas camadas LSTM que processam a sequ√™ncia em ambas as dire√ß√µes (passado para futuro e futuro para passado) para capturar depend√™ncias temporais complexas.
3. **Camadas de Dropout**: Inseridas entre as camadas LSTM para regulariza√ß√£o, ajudando a prevenir overfitting.
4. **Camadas Densas (Fully Connected)**: Camadas densas para processamento adicional das caracter√≠sticas aprendidas pelas LSTMs.
5. **Camada de Sa√≠da**: Uma camada densa final com fun√ß√£o de ativa√ß√£o `softmax` para classificar o gesto em uma das `N_ACTIONS` (n√∫mero de gestos) categorias.

O modelo √© treinado usando o otimizador Adam e a fun√ß√£o de perda `categorical_crossentropy`.

---

## üìà Resultados e Avalia√ß√£o

O script `TrainModel.py` fornece uma avalia√ß√£o do modelo treinado, incluindo:

* Precis√£o (accuracy) e perda (loss) nos conjuntos de treino e teste.
* Matriz de confus√£o para visualizar o desempenho por classe.
* Curvas de aprendizado (precis√£o e perda ao longo das √©pocas).

Os resultados podem variar dependendo da qualidade e quantidade dos dados coletados, da complexidade dos gestos e da arquitetura do modelo.

---

## üîÆ Poss√≠veis Melhorias Futuras

- [ ] Adicionar suporte para um vocabul√°rio maior de gestos.
- [ ] Implementar reconhecimento de frases completas (gram√°tica de sinais).
- [ ] Otimizar o modelo para melhor desempenho em dispositivos com menos recursos.
- [ ] Interface para tradu√ß√£o de texto para gestos (anima√ß√£o de avatar).
- [ ] Empacotar a aplica√ß√£o como um execut√°vel standalone (usando PyInstaller ou cx_Freeze).
- [ ] Melhorar a robustez a varia√ß√µes de ilumina√ß√£o, oclus√£o e √¢ngulos de c√¢mera.
- [ ] Integra√ß√£o com legendas em tempo real para v√≠deos ou chamadas.

---

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o muito bem-vindas! Se voc√™ tem ideias para melhorias, encontrou algum bug ou quer adicionar novas funcionalidades:

1. Fa√ßa um Fork do projeto.
2. Crie uma nova Branch (`git checkout -b feature/sua-feature`).
3. Fa√ßa commit das suas altera√ß√µes (`git commit -m 'Adiciona sua-feature'`).
4. Fa√ßa Push para a Branch (`git push origin feature/sua-feature`).
5. Abra um Pull Request.

Por favor, certifique-se de que seu c√≥digo segue as boas pr√°ticas e est√° bem comentado.

---

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` (voc√™ precisar√° criar um) para mais detalhes.

```
MIT License

Copyright (c) [2025] [Jo√£o Pedro Pereira Santiago ]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```


---

## üìß Contato

Jo√£o pedro Pereira Santiago ‚Äì  ‚Äì jpedropsss@gmail.com
